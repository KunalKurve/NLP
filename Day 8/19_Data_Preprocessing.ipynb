{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It was a nice rainy day.',\n",
       " 'The things are so beautiful in his point.',\n",
       " 'When your focus is clear, you win.',\n",
       " 'Many many happy returns of the day.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = ['It was a nice rainy day.', 'The things are so beautiful in his point.', 'When your focus is clear, you win.', 'Many many happy returns of the day.']\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'it': 1,\n",
       "             'rainy': 1,\n",
       "             'a': 1,\n",
       "             'was': 1,\n",
       "             'nice': 1,\n",
       "             'day': 2,\n",
       "             'point': 1,\n",
       "             'in': 1,\n",
       "             'beautiful': 1,\n",
       "             'are': 1,\n",
       "             'so': 1,\n",
       "             'things': 1,\n",
       "             'his': 1,\n",
       "             'the': 2,\n",
       "             'focus': 1,\n",
       "             'your': 1,\n",
       "             'is': 1,\n",
       "             'when': 1,\n",
       "             'clear': 1,\n",
       "             'win': 1,\n",
       "             'you': 1,\n",
       "             'returns': 1,\n",
       "             'many': 1,\n",
       "             'of': 1,\n",
       "             'happy': 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'day': 1,\n",
       " 'the': 2,\n",
       " 'many': 3,\n",
       " 'it': 4,\n",
       " 'was': 5,\n",
       " 'a': 6,\n",
       " 'nice': 7,\n",
       " 'rainy': 8,\n",
       " 'things': 9,\n",
       " 'are': 10,\n",
       " 'so': 11,\n",
       " 'beautiful': 12,\n",
       " 'in': 13,\n",
       " 'his': 14,\n",
       " 'point': 15,\n",
       " 'when': 16,\n",
       " 'your': 17,\n",
       " 'focus': 18,\n",
       " 'is': 19,\n",
       " 'clear': 20,\n",
       " 'you': 21,\n",
       " 'win': 22,\n",
       " 'happy': 23,\n",
       " 'returns': 24,\n",
       " 'of': 25}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = tokenizer.texts_to_matrix(lines)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = tokenizer.texts_to_sequences(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(max(seq, key=len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences(seq, maxlen=10, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences(seq, maxlen=10, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
